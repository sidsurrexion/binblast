#!/usr/bin/python
# Program:    matchoutput.py
# Programmer: Scott Miller
# Function:   A collection of bincompare output-transforming options

# binBLAST suite of binary analysis tools
# Copyright (C) 2006 Scott Miller
#  
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
# 
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
# 
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

def disassemble_entry(entry,returnbytes=False):
	"""Attempt to locate the file in entry and disassemble."""
	import mklib
	import os
	import time

	# For the moment, assume we're working with a relative
	#  directory (no leading /)
	basedir = ''
	# The directory where the archive was packed
	arcdir = ''
	# The directory where the ISO was mounted
	mntdir = ''

	try:
		# Mount distribution
		if entry.distname:
			isoname = basedir + entry.distname + '.iso'
			if os.path.isfile(isoname):
				mntdir = mklib.mount_isofile(basedir + entry.distname + '.iso') 
				basedir = mntdir

		# Unpack archive
		if entry.archive:
			arcdir = mklib.unpack_archive(basedir + entry.archive)
			basedir = arcdir

		# Disassemble file
		import objdumputil
		binaryFile = objdumputil.Objdump()
		instructions = binaryFile.disassemble(basedir + entry.file,returnbytes)

	finally:
		if arcdir: 
			os.system('rm -rf %s' % arcdir) 
		if mntdir: 
			os.system('umount -d %s' % mntdir) 
			# Umount is non-blocking
			time.sleep(1)
			os.rmdir(mntdir)

	return(instructions)

def text_aligned_disassembly(matches):
	"""Given a list of matches, [matchA, matchB, ...] print the associated
	disassembly side-by-side"""
	width = 50 - 2
	
	# Print the match information
	for i in range(len(matches)):
		print '|' + matches[i].entry.distname[-width:].center(width) + '|',
	print
	for i in range(len(matches)):
		print '|' + matches[i].entry.archive[-width:].center(width) + '|',
	print
	for i in range(len(matches)):
		print '|' + matches[i].entry.file[-width:].center(width) + '|',
	print
	for i in range(len(matches)):
		print '|' + ('Instruction offset: %u' % matches[i].offset).center(width) + '|',
	print
	for i in range(len(matches)):
		print '|' + ''.center(width) + '|',
	print

	# Get the disassembly for all matches
	disassembly = []
	for i in range(len(matches)):
		disassembly.append( disassemble_entry(matches[i].entry) )
	
	# Print the most recent label before the match starts
	for i in range(len(matches)):
		label = ''
		for j in range(-1,-(matches[i].offset + 1),-1):
			if len(disassembly[i][j + matches[i].offset]) == 3:
				label = '( %s )' % disassembly[i][j + matches[i].offset][2]
				break
		print '|' + label.center(width) + '|',
	print

	score = 0
	# Print the aligned matches
	for offset in range(0,matches[0].len):
		# Figure out the alignment
		aligned = []
		for i in range(len(matches)):
			aligned.append( disassembly[i][offset + matches[i].offset] )
		
		# Print the matches
		for instruction in aligned:
			line = ''
			if len(instruction) == 3:
				line = '   ' + \
				       instruction[0] + ' ' + \
				       instruction[1]
			elif len(instruction) == 4:
				line = instruction[2] + ':' + \
					instruction[0] + ' ' + \
					instruction[1]
			print '|' + line.ljust(width) + '|',
		#import karlinaltschul
		#from mklib import compact_instruction
		# Compute the score for these instructions
		#score += karlinaltschul.myscore([compact_instruction(aligned[0][0:2])],
		#		                [compact_instruction(aligned[1][0:2])])
											
		#print score
		print
	#print score
def safeLabel(s):
	"""Takes an input string and generates a label that is 
	safe for use with graphviz"""
	import md5
	hash = md5.new()
	hash.update(str(s))
	
	return('l%s' % hash.hexdigest())

class idxFile:
	"""A storage class for an .idx file generated by mklib.py
	that features an automatic cache of the entries.  
	idxFile[ idxOffset ] will retrieve the entry in the .idx file
	assocaited with that offset"""
	name = '' # The filename associated with this structure
	entry = [] # The cached entries for this file

	def __init__(self,idxfilename):
		self.name = idxfilename
		self.entry = []

	def __hash__(self):
		return(hash(self.name))

	def __eq__(a,b):
		if not b:
			return(False)
		else:
			return(a.name == b.name)
	def __ne__(a,b):
		return(not a==b)
	
	def __getitem__(self, offset):
		"""Search the current cache for the entry that would
		contain this offset *or* load from file if not found"""

		# Search to find cache entry
		# TODO: More efficient search
		for entry in self.entry:
			if entry.start <= offset and \
			   entry.start + entry.len > offset:
				return(entry)
			
		# Entry was not found, load from cache
		return(self.file_get_entry(offset))
		
	def file_get_entry(self, offset):
		"""Load an entry from file, adding to the entry cache
		if found."""
		# Open the index
		try:
			idxfile = open(self.name)
		# If this didn't work, try getting opening the same file
		#  in the local directory
		except IOError:
			dirs = self.name.split('/')
			if len(dirs) > 1:
				self.name = dirs[-1]
				return( self.file_get_entry(offset) )
			else:
				raise "Can't open %s" % self.name

		# Make sure offset is a long number
		offset = long(offset)
		
		# Search through each line
		oldlineidx = lineidx = 0
		oldline = line = idxfile.readline()
		while line:
			# Break the field into parts
			field = line.split(',')

			# Determine the offset of the next file
			lineidx = long(field[0])

			# If the starting offset of the next file is
			#  beyond the offset we're looking at, oldfield
			#  has the correct entry
			if offset < lineidx:
				break
			
			# This may have the entry, we won't know until
			#  after we look at the next line
			oldline = line
			oldlineidx = lineidx

			# Look at the next line
			line = idxfile.readline()

		# All done with this file
		idxfile.close()
		
		# Did we reach the end of the file?
		if oldlineidx == lineidx:
			# We need to get the length of the .dat file
			import os
			datfile = self.name[:-3] + 'dat'
			stat = os.stat(datfile)
			lineidx = stat.st_size / 4;
			#raise 'Unable to determine IDX entry length, truncated .idx file?'

		# Create a real entry
		newEntry = idxEntry()
		newEntry.fromIDX(oldline)
		newEntry.len = lineidx - oldlineidx
		newEntry.idx = self
		
		# Figure out where this should go in the cache
		for i in range(len(self.entry)):
			# If the starting index is now greater
			#  than this index...
			if self.entry[i].start < newEntry.start:
				# ...insert before this index
				self.entry.insert(i,newEntry)
				return(newEntry)

		# Wasn't inserted yet, place at end
		self.entry.append(newEntry)
		return(newEntry)
		
		
class idxEntry:
	"""A storage class for holding IDX file entries"""
	idx = None
	start = 0L
	len = 0L
	file = ''
	archive = ''
	distname = ''

	def __init__(self):
		self.idx = None
		self.start = 0L
		self.len = 0L
		self.file = ''
		self.archive = ''
		self.distname = ''

	def __hash__(self):
		if self.idx:
			return(hash( ',%s,%li' % (self.toIDX(), hash(self.idx) ) ))
		else:
			return(hash( self.toIDX() ))
	def __eq__(a,b):
		return ( a.idx == b.idx and
			a.start == b.start and
			a.len == b.len and
			a.file == b.file and
			a.archive == b.archive and
			a.distname == b.distname)

	def __ne__(a,b):
		return(not a==b)
	def __repr__(self):
		return( "{ 'start':%u, 'len':%u, 'file':'%s', 'archive':'%s','distname':'%s' }" % ( self.start, self.len, self.file, self.archive, self.distname ) )
		
	def fromIDX(self, str):
		"""Make this idxEntry reflect the information from
		str, a line out of a .idx file generated by mklib
		"""

		# Make sure everything is clean
		self.start = 0L
		self.len = 0L
		self.idx = None
		self.file = ''
		self.archive = ''
		self.distname = ''
		
	
		# These are comma separated
		parts = str.split(',')
		
		# Get as much out of the parts as is available
		try:
			self.start = long( parts.pop(0) )
			self.file = parts.pop(0).strip()
			self.archive = parts.pop(0).strip()
			self.distname = parts.pop(0).strip()
				
		except IndexError:
			pass
			
	def toIDX(self):
		"""Return this entry as a string suitable for an
		IDX file"""
		str = ''
		str += '%lu' % self.start
		if self.file:
		 str += ',%s' % self.file
		 if self.archive:
		  str += ',%s' % self.archive
		  if self.distname:
		   str += ',%s' % self.distname
		return str

	def filter(self,matches):
		"""Given a dictionary of matches, return another 
		dictionary that only contains matches associated
		with this entry."""
		retmatches = {}
		for key in matches.keys():
			if matches[key].entry == self:
				retmatches[key] = matches[key]
			
		return(retmatches)
	
class bincompareMatch:
	"""A storage class for holding bincompare matches"""
	entry = None 
	offset = 0L
	len = 0
	score = 0
	targets = []
	a = False

	def __init__(self, dEntry, dOffset, dLen, dScore):
		self.entry = dEntry
		self.offset = dOffset
		self.len = dLen
		self.score = dScore
		self.targets = []
		self.a = False
		
	def __hash__(self):
		if self.entry:
			return(hash( '%uli,%uli,%li,%li' % (
				self.offset,
				self.len,
				self.score,
				hash(self.entry) ) ))
		else:
			return(hash( '%uli,%uli,%li' % (
				self.offset,
				self.len,
				self.score ) ))
	def __eq__(a,b):
		return( a.entry == b.entry and
			a.offset == b.offset and
			a.len == b.len and
			a.score == b.score )
	def __ne__(a,b):
		return(not a==b)
	def __repr__(self):
		ret = "{ 'offset':%u, 'len':%u, 'score':%u" % ( \
			self.offset, self.len, self.score ) 
		if self.entry:
			ret += "'entry':%s" % self.entry
		ret += ' }'
		return(ret)
	
	def merge(self, other):
		"""Remove empty targets from other and add them
		to self, allowing other to be removed.  If other
		!= self"""
		if(self == other):
			# Go through all targets
			for j in range(len(other.targets)):
				target = other.targets.pop()

				# Remove all instances of `other' in the
				#  back-links, target.targets
				for i in range(target.targets.count(other)):
					target.targets.remove(other)

				# Add self in the back-links, target.targets
				#  but only if it's not there
				if target.targets.count(self) == 0:
					target.targets.append(self)
				# Add target in self.targets only if
				#  it's not there
				if self.targets.count(target) == 0:
					self.targets.append(target)

		else:
			raise 'self != other'
	
def bincompare_matches(bincompare):
	"""Given a filestream `bincompare' that has the output of 
	bincompare, return a tuple of 
	[dictionary of bincompareMatch'es indexed by the hash value of the entry	, idxfiles]"""
	
	# We've not seen the match files yet
	fileA = ''
	fileB = ''

	# We've no matches for this yet
	matches = {}

	# We've no IDX files seen
	idxfiles = {}

	# We're going to start for looking for the first file
	lookingFor = 'fileA'

	# Start looking at the input line by line
	line = bincompare.readline()
	while line:
		# If we see a line that starts with `File ', we need to
		#  look for a new file A and B
		if line[0:5] == 'File ' and \
		   lookingFor not in ['fileA', 'fileB']:
			lookingFor = 'fileA'

		if lookingFor in ['fileA','fileB'] :
			# The file name is everything after this file until
			#  an offset is seen
			try:
				(filename, unused) = line[5:].split(', offset ',2)
				(offset, unused) = unused.split(', len',2)
				offset = long(offset)
				
				idxfilename = filename[:-4] + '.idx'
				# See if we've got this cached
				if idxfiles.has_key(idxfilename):
					dfile = idxfiles[idxfilename]
				else:
					dfile = idxFile(idxfilename)
					idxfiles[idxfilename] = dfile
					
				# Now look for fileB
				if lookingFor == 'fileA':
					fileA = dfile
					offsetA = offset
					lookingFor = 'fileB'
				else:
					fileB = dfile
					offsetB = offset
					lookingFor = 'time'
					
			except ValueError:
				lookingFor = 'fileA'

		elif lookingFor == 'time':
			# If we see `matches above', this is a filtered
			#  output. 
			if 'Matches above' in line:
				continue
			# If the time is missing here, this is most
			#  likely the output from bincompare-dirout.
			#  This means that numbers are relative to the
			#  file's offsets and not absolute within the
			#  file.
			elif not 'Comparison took ' in line:
				lookingFor = 'match'
				continue
			#Otherwise, zero the offsets (the matches are absolute)
			# expect matches
			else:
				offsetA = 0
				offsetB = 0
				lookingFor = 'match'

		elif lookingFor == 'match':
			fields = line.split(',')
			fields[-1] = fields[-1].rstrip()

			# If we have four fields, this is some sort of
			#  match
			if len(fields) >= 4:
				# We need the IDX entries involved
				entryA = fileA[ long(fields[0]) + offsetA ]
				entryB = fileB[ long(fields[1]) + offsetB ]
				
				# Figure out the in-file offsets
				offA = long(fields[0]) + offsetA - entryA.start
				offB = long(fields[1]) + offsetB - entryB.start
		
				# Create new matches for these
				matchA = bincompareMatch(entryA, \
						offA, \
						long(fields[3]), \
						long(fields[2]) )
				matchA.a = True
				matchB = bincompareMatch(entryB, \
						offB, \
						long(fields[3]), \
						long(fields[2]) )
			
				# Do not consider trivial matches
				if True: # matchA != matchB:
					hashA = safeLabel(matchA)
					hashB = safeLabel(matchB)
					matchA.targets.append(matchB)
					matchB.targets.append(matchA)

					if matches.has_key(hashA):
						if matches[hashA] == \
						   matchA:
							matches[hashA].merge(matchA)
							matchA = None
						else:

							raise 'Hash collision, %s / %s' % (matchA, matches[hashA])
					else:
						matches[hashA] = matchA
						
					if matches.has_key(hashB):
						if matches[hashB] == \
						   matchB:
							matches[hashB].merge(matchB)
							matchB = None
						else:
							raise 'Hash collision, %s / %s' % (matchB, matches[hashB])
					else:
						matches[hashB] = matchB
				else:
					matchA = None
					matchB = None

		# filterbin compare can throw in some extras
		elif 'Filtered, sorted results' in line:
			pass
		# Ignore blank lines
		elif line.strip() == '':
			pass
		# We've no idea of what this was
		else:
			lookingFor = 'fileA'
			continue

		# Get the next line
		line = bincompare.readline()

	return(matches,idxfiles)

def graph(matches,idxfiles,output):
	"""Using a match dictionary, indexed by the hash of the matches
	and valued by bincompareMatch'es, and a listing of the idxfiles
	involved create a graphviz description for this graph and write it 
	to the FileStream output.
	"""
	
	# This is an undirected graph
	output.write('graph G {\n')

	# Loop through all of the idx files considered
	for idxfile in idxfiles.values():
		# ...and each entry in those files
		for entry in idxfile.entry:
			# Get only the matches for this entry	
			fmatches = entry.filter(matches)

			# Add every entry into a dictionary of offsets
			offsetList = {}
			for f in fmatches.values():
				if offsetList.has_key(f.offset):
					offsetList[f.offset].append(f)
				else:
					offsetList[f.offset] = [ f ]

			# Get an ordered list of the offsets
			if len(offsetList) == 0: 
				continue
			
			offsetsOrdered = offsetList.keys()
			offsetsOrdered.sort()
			
			# Make a subgraph cluster for this file
			file = entry.file
			output.write('subgraph cluster_%s {\n' % safeLabel(file))
			output.write('style=filled;\n')
			output.write('color=lightgrey;\n')
			output.write('label = "%s";\n' % (file) )
			
			# Link the offsets together (in order)
			output.write( safeLabel(file + str(offsetsOrdered[0])) )
			for thisOffset in offsetsOrdered[1:]:
				output.write(' -- %s' % safeLabel(file + str(thisOffset)) )
			output.write(';\n')
			output.write('}\n')

			# Create nodes for each of the matches
			for thisOffset in offsetsOrdered:
				output.write('\"%s\" [ \n' % safeLabel(file + str(thisOffset)) )
				output.write('label="%u | ' % (thisOffset))
				lens = []
				for match in offsetList[thisOffset]:
					if match.len  not in lens:
						lens.append(match.len)
				lens.sort()
				output.write('%u' % lens[0])
				for dlen in lens[1:]:
					output.write(',%u' % dlen)
				output.write('"\n')
				output.write('shape="record"\n')
				output.write('];\n');
			output.write('\n\n')

			# Add match interdependencies
			for f in fmatches.values():
				motif = None
				for target in f.targets:
					if target.entry.file[0:6] == 'motif_':
						motif = target
				if not motif:
					for target in f.targets:
						output.write('%s -- %s;\n' % (
							safeLabel(file + str(f.offset) ),
							safeLabel(target.entry.file +
								  str(target.offset) )
							))
					

						# Remove the back-link to prevent
						#  redrawing the same line
						if target.targets.count(f) > 0:
							target.targets.remove(f)
						else:
							pass
				else:
					output.write('%s -- %s;\n' % ( \
						safeLabel(file + str(f.offset)),\
						safeLabel(motif.entry.file + \
							file + str(f.offset)) \
						))
					output.write('"%s" [ \n' % \
						safeLabel(motif.entry.file + \
							file + str(f.offset)) \
						)
					output.write('shape=ellipse\n')
					output.write('label="%s"\n' %
						motif.entry.file[6:] )
					output.write('];\n')

			output.write('\n\n')
	# All done
	output.write('}\n')	

def motif_name(number):
	"""Convert a number into A, B, ..., AA, ..., AAA, ... etc"""
	modulus = number % 26
	div = number / 26
	if div >= 26:
		raise 'Too many motifs!'

	str = ''
	for i in range(div + 1):
		str += chr( ord('A') + modulus )
		
	return(str)
	
def add_motifs(matches,threshold):
	"""Given a match dictionary, generate motif targets for any
	links that have a target order higher than threshold."""
	
	num = 0
	for match in matches.values():
		if len( match.targets ) > threshold:
			motif = None
			for target in match.targets:
				if target.entry.file[0:6] == 'motif_':
					motif = target
			if not motif:
				newMotif = idxEntry()	
				newMotif.file = 'motif_%s' % motif_name(num)
				newMatch = bincompareMatch(0,0,0,0)
				newMatch.entry = newMotif
			
				for target in match.targets:
					if newMatch not in target.targets:
						target.targets.append(newMatch)
					if target not in newMatch.targets:
						newMatch.targets.append(target)
				if newMatch not in match.targets:
					match.targets.append(newMatch)
				if match not in newMatch.targets:
					newMatch.targets.append(match)
				num += 1	

def coverage(idxentry,matches):
	"""Compute the coverage, the percentage of instructions that
	are included by the targets of matches."""
	coverage = []
	# Create an array representing each instruction of idxentry
	for i in range(idxentry.len):
		coverage.append(False)
		
	# Look through the targets of all matches...
	for match in matches.values():
	 for target in match.targets:
		# If this does not target this entry, move on
		if target.entry != idxentry:
			continue
		# Otherwise, mark the instructions it targets as covered
		for i in range(target.offset,target.offset + target.len):
			coverage[i] = True
			
	# Sum up the number of instructions that have been covered		
	similar = 0
	for i in range(idxentry.len):
		if coverage[i]:
			similar += 1

	# Return the similarity
	# Note: idxentry.len includes the null-terminator, so it's
	#  length is one too long
	return( 1.0 * similar / (idxentry.len - 1))

def similarity(matches,idxfiles,outfile):
	"""Create a similarity table, suitable for LaTeX, and write
	it to outfile"""
	files = []

	# Get a list of all the possible files
	for idxfile in idxfiles.values():
		for file in idxfile.entry:
			files.append(file)

	# Print the column labels
	outfile.write(' &')
	for j in files:
		outfile.write(' %s (%s) &' % (j.file, j.archive))
	outfile.write('\\\\\n')	

	# Print the rows
	for i in files:
		outfile.write(' %s (%s) &' % (i.file, i.archive))
		for j in files:
			# Compute the coverage of i
			a = coverage(i,j.filter(matches))
			
			# Compute the coverage of j
			b = coverage(j,i.filter(matches))

			outfile.write(' %g &' % (a * b))
		outfile.write('\\\\\n')

def distance(matches,idxfiles,outfile):
	"""Create a distance matrix, suitable for the Phylip suite
	of phylogenetic software, and write it to outfile"""
	files = []

	# Get a list of all the possible files
	for idxfile in idxfiles.values():
		for file in idxfile.entry:
			files.append(file)

	outfile.write('%u\n' % len(files))

	# Print the rows
	for i in files:
		#(unused,name,unused2) = i.archive.split('-',3)
		#outfile.write('%10s' % name)
		outfile.write('%s ' % i.file)
		for j in files:
			# Compute the coverage of i
			a = coverage(i,j.filter(matches))
			
			# Compute the coverage of j
			b = coverage(j,i.filter(matches))

			if (a*b):
				import math
				outfile.write('%g ' % (1.0 / math.sqrt(a * b) - 1.0))
			else:
				outfile.write('0 ')
		outfile.write('\n')

def set_args():
	from optparse import OptionParser
	parser = OptionParser()

	parser.add_option("-s","--similarity",
			  dest="similarity",
			  action="store_true",
			  default=False,
			  help="Create a similarity table (LaTeX format)")
	parser.add_option("-d","--distance",
			  dest="distance",
			  action="store_true",
			  default=False,
			  help="Create a distance table (PHYLIP format)")
	parser.add_option("-m","--motifs",
			  dest="motifs",
			  action="store_true",
			  default=False,
			  help="Create motif groups in graph")
	parser.add_option("-g","--graph",
			  dest="graph",
			  action="store_true",
			  default=False,
			  help="Create a graph of the matches (graphviz dot format)")
	parser.add_option("-a","--assembly",
			  dest="assembly",
			  action="store_true",
			  default=False,
			  help="Print aligned assembly (requires IDXFILEA STARTA,LENA IDXFILEB STARTB,LENB as arguments)")
	(options,args) = parser.parse_args()
	if not (options.similarity or options.distance or options.graph or options.assembly):
		parser.error('No output specified')

	return (options,args)

if __name__ == "__main__":
	(options, args) = set_args()

	if len(args) == 4:
		# Get the IDX files
		fileA = idxFile( args[0] )
		if args[2] != args[0] and args[2] != 'same':
			fileB = idxFile( args[2] )
		else:
			fileB = fileA

		# Get the start and lengths
		(startA, lenA) = args[1].split(',')
		startA = long(startA)
		lenA = long(lenA)
		(startB, lenB) = args[3].split(',')
		startB = long(startB)
		lenB = long(lenB)

		# We need the IDX entries involved
		entryA = fileA[ startA ]
		entryB = fileB[ startB ]
		
		# Figure out the in-file offsets
		offA = startA - entryA.start
		offB = startB - entryB.start

		# Create new matches for these
		matchA = bincompareMatch(entryA, \
				offA, \
				lenA, \
				0 )
		matchB = bincompareMatch(entryB, \
				offB, \
				lenB, \
				0)
		
		# Generate the results
		text_aligned_disassembly([matchA, matchB])
			
	if len(args) == 0:
		import sys
		(matches, idxfiles) = bincompare_matches(sys.stdin)

		if options.similarity:
			similarity(matches, idxfiles, sys.stdout)
		if options.distance:
			distance(matches, idxfiles, sys.stdout)
		if options.motifs:
			add_motifs(matches, len(idxfiles))
		if options.graph:
			graph(matches,idxfiles,sys.stdout)
